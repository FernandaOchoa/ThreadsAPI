{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An치lisis de sentimientos con Text Analytics\n",
    "By Fernanda Ochoa.\n",
    "\n",
    "El presente notebook, desarrolla un ejemplo de como utilizar la data extra칤da por ThreadsAPI con la implementaci칩n de ```getData.py``` y el notebook de limpieza de datos ```threads.ipynb``` para trabajarlo con los servicios cognitivos de Azure.\n",
    "\n",
    "[Azure Cognitive Services](https://learn.microsoft.com/es-MX/azure/cognitive-services/) es una plataforma basada en la nube que ofrece servicios de inteligencia artificial (IA). Estos servicios nos permiten integrar capacidades cognitivas en aplicaciones sin necesidad de tener conocimientos profundos de IA o ciencia de datos.\n",
    "\n",
    "\n",
    "#### Categor칤as de servicios cognitivos\n",
    "\n",
    "Los servicios cognitivos se pueden clasificar en cinco 치reas principales:\n",
    "\n",
    "+ [Voz](https://learn.microsoft.com/es-MX/azure/cognitive-services/): \n",
    "  + Voz a texto\n",
    "  + Texto a voz\n",
    "  + Traducci칩n de voz\n",
    "  + Reconocimiento de voz\n",
    "+ [Lenguaje](https://learn.microsoft.com/es-MX/azure/cognitive-services/):\n",
    "  + Reconocimiento de entidades\n",
    "  + An치lisis de opiniones\n",
    "  + Respuestas a preguntas\n",
    "  + Reconocimiento de lenguaje conversacional\n",
    "  + Traductor\n",
    "+ [Visi칩n](https://learn.microsoft.com/es-MX/azure/cognitive-services/):\n",
    "  + An치lisis de Im치genes y Video\n",
    "  + Modelos personalizados\n",
    "+ [Decisi칩n](https://learn.microsoft.com/es-MX/azure/cognitive-services/):\n",
    "  + Detector de anomal칤as\n",
    "  + Moderador de contenido\n",
    "  + Personalizer\n",
    "+ [Servicio Azure OpenAI](https://learn.microsoft.com/es-MX/azure/cognitive-services/openai/concepts/models):\n",
    "  + Dall E\n",
    "  + GPT-4\n",
    "  + GPT-3.5\n",
    "  + Incrustaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Herramientas\n",
    "\n",
    "* Pandas\n",
    "    * Es una biblioteca considerada una extensi칩n de Numpy para la manipulaci칩n y an치lisis de datos con Python.\n",
    "    * [Pandas Docs](https://pandas.pydata.org/)\n",
    "* Azure AI TextAnalytics:\n",
    "  * Es un servicio basado en la nube que proporciona funciones de procesamiento de lenguaje natural (NLP) para comprender y analizar texto.\n",
    "  * Es necesaria una suscripci칩n de Azure para obtener las credenciales como ```APIKey``` y ```Url Endpoint```.\n",
    "  * [Azure AI TextAnalytics Docs](https://pypi.org/project/azure-ai-textanalytics/)\n",
    "* Dot env:\n",
    "  * Biblioteca para leer los pares clave-valor de un archivo .env y  establecerlos como variables de entorno. Ayuda en el desarrollo de aplicaciones siguiendo los principios de 12 factores.\n",
    "  * [Dot env Docs](https://pypi.org/project/python-dotenv/)\n",
    "\n",
    "#### Requisitos\n",
    "* Dataset: Conjunto de datos en csv con el que vamos a trabajar.\n",
    "  * Puedes encontrar un ejemplo en la carpeta: ```data``` en formato ```csv```.\n",
    "* Suscripci칩n de Azure: Ingresar al [portal de azure](https://portal.azure.com), crear una suscripci칩n, agregar una tarjeta (usamos la tarifa gratuita por lo que no hay costos) y listo.\n",
    "* [Activar suscripci칩n](https://azure.microsoft.com/es-mx/free/)\n",
    "* Credenciales text analytics: \n",
    "  * Ingresar al [portal de azure](https://portal.azure.com)\n",
    "  * [Seguir el tutorial](https://learn.microsoft.com/es-mx/azure/cognitive-services/cognitive-services-apis-create-account?tabs=multiservice%2Canomaly-detector%2Clanguage-service%2Ccomputer-vision%2Cwindows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instalamos las Bibliotecas\n",
    "\n",
    "* [Text analytics](https://pypi.org/project/azure-ai-textanalytics/):\n",
    "  * Visual Studio Code: ```%pip install azure-ai-textanalytics```\n",
    "  * Google Colab: ```!pip install azure-ai-textanalytics```\n",
    "* [Dot env](https://pypi.org/project/python-dotenv/): \n",
    "  * Visual Studio Code: ```%pip install python-dotenv```\n",
    "  * Google Colab: ```!pip install python-dotenv```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credenciales\n",
    "\n",
    "Una vez creados los servicios cognitivos en el [portal de azure](https://portal.azure.com). Se debe crear en la ra칤z del proyecto un archivo llamado ```.env```, este archivo de configuraci칩n, contiene las variables de entorno del proyecto, es decir las credenciales de acceso al API de los servicios cognitivos.\n",
    "\n",
    "``` Contenido de mi archivo .env\n",
    "API_KEY = 'Reemplazar por tus credenciales'\n",
    "API_ENDPOINT = 'Reemplazar por tus credenciales'\n",
    "API_REGION = 'Reemplazar por tus credenciales'\n",
    "```\n",
    "\n",
    "Recuerda crear el archivo: ```.gitignore``` y a침adir tu archivo ```.env``` si planeas subirlo a un repositorio de git.\n",
    "\n",
    "``` Contenigo de mi archivo .gitignore\n",
    "# Ignorar archivo .env que puede contener informaci칩n sensible\n",
    ".env\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in /Users/fernandaochoa/Library/Python/3.9/lib/python/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/fernandaochoa/Library/Python/3.9/lib/python/site-packages (from requests) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/fernandaochoa/Library/Python/3.9/lib/python/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fernandaochoa/Library/Python/3.9/lib/python/site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/fernandaochoa/Library/Python/3.9/lib/python/site-packages (from requests) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Instalamos requests\n",
    "%pip install --upgrade requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: azure-ai-textanalytics in /Users/fernandaochoa/Library/Python/3.9/lib/python/site-packages (5.3.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in /Users/fernandaochoa/Library/Python/3.9/lib/python/site-packages (from azure-ai-textanalytics) (1.28.0)\n",
      "Requirement already satisfied: azure-common~=1.1 in /Users/fernandaochoa/Library/Python/3.9/lib/python/site-packages (from azure-ai-textanalytics) (1.1.28)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.6.1 in /Users/fernandaochoa/Library/Python/3.9/lib/python/site-packages (from azure-ai-textanalytics) (0.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /Users/fernandaochoa/Library/Python/3.9/lib/python/site-packages (from azure-ai-textanalytics) (4.7.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in /Users/fernandaochoa/Library/Python/3.9/lib/python/site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/fernandaochoa/Library/Python/3.9/lib/python/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/fernandaochoa/Library/Python/3.9/lib/python/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fernandaochoa/Library/Python/3.9/lib/python/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/fernandaochoa/Library/Python/3.9/lib/python/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Instalamos azure-ai-textanalytics\n",
    "%pip install azure-ai-textanalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in /Users/fernandaochoa/Library/Python/3.9/lib/python/site-packages (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Instalamos python-dotenv\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importamos las bibliotecas y variables de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para importar las variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las bibliotecas de Azure: Credentials y TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la biblioteca pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las credenciales del API\n",
    "endpoint = os.getenv('API_ENDPOINT')\n",
    "apiKey = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autenticamos el cliente\n",
    "client = TextAnalyticsClient(endpoint=endpoint, credential=AzureKeyCredential(apiKey))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos nuestro csv con la data\n",
    "data = pd.read_csv('../data/cleanData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructuramos el dataframe con las columnas de inter칠s: Text y Likes\n",
    "data.columns = ['Thread', 'Likes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la longitud de cada texto\n",
    "data['len'] = data['Thread'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos la posici칩n de la columna len al lado de la columna de texto del thread, obteniendo el nombre de la columna en la posici칩n 2\n",
    "columnToMove = data.columns[2]\n",
    "\n",
    "col = data.pop(columnToMove)\n",
    "\n",
    "data.insert(1, columnToMove, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thread</th>\n",
       "      <th>len</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amanecimos con buenas noticias 游눩游낗Ya podemos es...</td>\n",
       "      <td>141</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Listo, ya solo documento algunos ejemplos con ...</td>\n",
       "      <td>231</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Thread  len  Likes\n",
       "0  Amanecimos con buenas noticias 游눩游낗Ya podemos es...  141     14\n",
       "1  Listo, ya solo documento algunos ejemplos con ...  231     33"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobamos el cambio de lugar de columnas\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos el dataframe a una lista \n",
    "textThreads = data[\"Thread\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista para guardar los sentimientos de las revisiones\n",
    "sentiments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamos el texto por lotes de 10 (l칤mite de la API)\n",
    "for i in range(0, len(textThreads), 10):\n",
    "    batch = textThreads[i : i + 10]\n",
    "    result = client.analyze_sentiment(batch, show_opinion_mining=True)\n",
    "    docs = [doc for doc in result if not doc.is_error]\n",
    "\n",
    "    for idx, doc in enumerate(docs):\n",
    "        sentiments.append(doc.sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si la cantidad de threads no son un m칰ltiplos de 10, es posible que la longitud de\n",
    "# 'sentiments' sea menor que la longitud de 'threads'. En este caso, agregamos como sentimiento\n",
    "# desconocido para los threads restantes.\n",
    "while len(sentiments) < len(textThreads):\n",
    "    sentiments.append(\"desconocido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos la columna Sentiment\n",
    "data['Sentiment'] = sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thread</th>\n",
       "      <th>len</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amanecimos con buenas noticias 游눩游낗Ya podemos es...</td>\n",
       "      <td>141</td>\n",
       "      <td>14</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Listo, ya solo documento algunos ejemplos con ...</td>\n",
       "      <td>231</td>\n",
       "      <td>33</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ya les ando preparando el repo para que puedan...</td>\n",
       "      <td>183</td>\n",
       "      <td>11</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>쮺칩mo va su s치bado?, 쯏a tomaron caf칠?</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Si llego a mil seguidores el fin les explico c...</td>\n",
       "      <td>215</td>\n",
       "      <td>31</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Thread  len  Likes Sentiment\n",
       "0  Amanecimos con buenas noticias 游눩游낗Ya podemos es...  141     14  positive\n",
       "1  Listo, ya solo documento algunos ejemplos con ...  231     33   neutral\n",
       "2  Ya les ando preparando el repo para que puedan...  183     11   neutral\n",
       "3             쮺칩mo va su s치bado?, 쯏a tomaron caf칠?   38     15   neutral\n",
       "4  Si llego a mil seguidores el fin les explico c...  215     31   neutral"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos el dataframe con la columna Sentiment\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si as칤 lo deseamos, podemos exportarlo a un csv, complementarlo con m치s api's, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threads API: An치lisis de Sentimientos con Azure y Threads API\n",
    "\n",
    "Material desarrollado por: Fernanda Ochoa.\n",
    "\n",
    "Contacto:\n",
    "* GitHub: [FernandaOchoa](https://github.com/FernandaOchoa)\n",
    "* Twitter: [@imonsh](https://twitter.com/imonsh)\n",
    "* Instagram: [fherz8a](https://instagram.com/fherz8a)\n",
    "* Linkedin: [Fernanda Ochoa](https://www.linkedin.com/in/fernandaochoa8/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
